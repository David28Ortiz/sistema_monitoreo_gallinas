{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KK7F9ZxiAsL"
      },
      "source": [
        "##**Modelo de Detecci√≥n**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Librer√≠as"
      ],
      "metadata": {
        "id": "jdzBvkup3sCh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "IA51hFbzjwcl"
      },
      "outputs": [],
      "source": [
        "# Instalar ultralytics para YOLO\n",
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "DCzPsGBYn6Di"
      },
      "outputs": [],
      "source": [
        "# Importar librer√≠as\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "from google.colab import drive\n",
        "import os\n",
        "import time\n",
        "import cv2\n",
        "import numpy as np\n",
        "import yaml\n",
        "import colorsys\n",
        "import torch.backends.cudnn as cudnn\n",
        "from PIL import Image\n",
        "from collections import defaultdict\n",
        "import albumentations as A\n",
        "import random\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Acceso a Gooogle Drive"
      ],
      "metadata": {
        "id": "RzMqVFLR4JaY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0SSUXTVsHxe"
      },
      "outputs": [],
      "source": [
        "# Montar Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Seleccionamos el modelo YOLO."
      ],
      "metadata": {
        "id": "U-rHIm6R4UFZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "F0e4CQG6oer-"
      },
      "outputs": [],
      "source": [
        "# Configurar los par√°metros del modelo YOLOV11X\n",
        "model = YOLO('yolo11x.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Aumento de las im√°genes para el entrenamiento"
      ],
      "metadata": {
        "id": "-bFNpNNBheQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rutas de carpetas en Google Drive\n",
        "train_folder = \"/content/drive/MyDrive/Colab Notebooks/yolov8_tracking/yolov8_detection/hen_detection_dataset/train/images\"\n",
        "label_folder = \"/content/drive/MyDrive/Colab Notebooks/yolov8_tracking/yolov8_detection/hen_detection_dataset/train/labels\"\n",
        "os.makedirs(train_folder, exist_ok=True)\n",
        "os.makedirs(label_folder, exist_ok=True)\n",
        "\n",
        "# Obtener lista de im√°genes en train\n",
        "image_files = [f for f in os.listdir(train_folder) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
        "random.shuffle(image_files)  # Mezclar im√°genes para selecci√≥n aleatoria"
      ],
      "metadata": {
        "id": "OKghAfvthh0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# N√∫mero total de im√°genes en train\n",
        "total_images = len(image_files)\n",
        "images_per_augmentation = round(total_images / 4)  # Distribuir im√°genes equitativamente entre 4 t√©cnicas\n",
        "\n",
        "# Dividir im√°genes en grupos din√°micos seg√∫n la cantidad en train\n",
        "noise_images = image_files[:images_per_augmentation]\n",
        "gray_images = image_files[images_per_augmentation:images_per_augmentation*2]\n",
        "brightness_images = image_files[images_per_augmentation*2:images_per_augmentation*3]\n",
        "saturation_images = image_files[images_per_augmentation*3:]"
      ],
      "metadata": {
        "id": "kM_sNyNLhlyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir transformaciones\n",
        "transforms = {\n",
        "    \"noise\": A.GaussNoise(var_limit=(10.0, 50.0), p=1.0),\n",
        "    \"gray\": A.ToGray(p=1.0),\n",
        "    \"brightness\": A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=1.0),\n",
        "    \"saturation\": A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=30, val_shift_limit=20, p=1.0)\n",
        "}"
      ],
      "metadata": {
        "id": "tE83yVi0ht1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicar transformaciones y guardar im√°genes con etiquetas\n",
        "def apply_augmentation(image_list, transform, prefix):\n",
        "    for img_file in image_list:\n",
        "        img_path = os.path.join(train_folder, img_file)\n",
        "        label_path = os.path.join(label_folder, os.path.splitext(img_file)[0] + \".txt\")\n",
        "\n",
        "        image = cv2.imread(img_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        augmented = transform(image=image)['image']\n",
        "        output_img_path = os.path.join(train_folder, f\"{prefix}_{img_file}\")\n",
        "        Image.fromarray(augmented).save(output_img_path)\n",
        "\n",
        "        # Copiar etiqueta si existe\n",
        "        if os.path.exists(label_path):\n",
        "            output_label_path = os.path.join(label_folder, f\"{prefix}_{img_file.replace('.jpg', '.txt').replace('.png', '.txt').replace('.jpeg', '.txt')}\")\n",
        "            shutil.copy(label_path, output_label_path)\n",
        "\n",
        "apply_augmentation(noise_images, transforms[\"noise\"], \"noise\")\n",
        "apply_augmentation(gray_images, transforms[\"gray\"], \"gray\")\n",
        "apply_augmentation(brightness_images, transforms[\"brightness\"], \"brightness\")\n",
        "apply_augmentation(saturation_images, transforms[\"saturation\"], \"saturation\")\n",
        "\n",
        "print(f\"Aumento de im√°genes completado. Total de im√°genes generadas: {len(os.listdir(train_folder)) - total_images}\")"
      ],
      "metadata": {
        "id": "EuE4JOfch_p5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Entrenamiento del modelo de detecci√≥n"
      ],
      "metadata": {
        "id": "vbblrxDmiE-C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMLU2mqBos69"
      },
      "outputs": [],
      "source": [
        "model.train(\n",
        "    data='/content/drive/MyDrive/Colab Notebooks/yolov8_tracking/yolov8_detection/data.yaml',   # Archivo de configuraci√≥n de los datos\n",
        "    epochs=100,                             # N√∫mero de √©pocas de entrenamiento\n",
        "    batch=32,                               # Tama√±o del batch (ajusta si ves que consume demasiada RAM)\n",
        "    imgsz=640,                             # Tama√±o de la imagen (640x640 en este caso)\n",
        "    cache=True                             # Cachear las im√°genes para reducir la carga de lectura\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6vwgVkuc1zl"
      },
      "source": [
        "###Realizamos las predicciones a partir del modelo 'best.pt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "gfjlMPY2aChV"
      },
      "outputs": [],
      "source": [
        "# Cargar el modelo entrenado (despu√©s del entrenamiento)\n",
        "model = YOLO('/content/drive/MyDrive/Colab Notebooks/yolov8_tracking/yolov8_detection/runs_model_x/weights/best.pt')\n",
        "\n",
        "# Directorio de las im√°genes de prueba\n",
        "test_images_path = '/content/drive/MyDrive/Colab Notebooks/yolov8_tracking/yolov8_detection/test/images'\n",
        "\n",
        "# Realizar predicciones en las im√°genes de prueba\n",
        "results = model.predict(\n",
        "    source=test_images_path,       # Ruta a la carpeta de im√°genes de prueba\n",
        "    conf=0.5,                      # Umbral de confianza para detecciones\n",
        "    save=True,                     # Guardar las im√°genes con los resultados\n",
        "    save_txt=True,                 # Guardar las etiquetas predichas en formato .txt\n",
        "    project='/content/drive/MyDrive/Colab Notebooks/yolov8_tracking/yolov8_detection/test',  # Carpeta donde se guardar√°n los resultados\n",
        "    name='predictions'             # Subcarpeta donde se almacenar√°n los resultados\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xz_gPDW7dBjb"
      },
      "source": [
        "###Realizamos el conteo de las gallinas en cada imagen que predijo el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "iHd-gRpEca18"
      },
      "outputs": [],
      "source": [
        "# Contar gallinas por imagen\n",
        "image_hen_counts = {}\n",
        "for result in results:\n",
        "    image_name = result.path.split(\"/\")[-1]  # Obtener el nombre de la imagen\n",
        "    detections = result.boxes  # Obtener las detecciones\n",
        "    count = len(detections)  # Contar las detecciones en esta imagen\n",
        "    image_hen_counts[image_name] = count  # Guardar el conteo\n",
        "\n",
        "# Mostrar resultados\n",
        "for image, count in image_hen_counts.items():\n",
        "    print(f\"{image}: {count} gallinas detectadas\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Ruta de nuestro Modelo de detecci√≥n"
      ],
      "metadata": {
        "id": "rZWudXsiahh8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurar el modelo YOLOv11 con tu modelo entrenado\n",
        "model_path = '/content/drive/MyDrive/Colab Notebooks/yolov8_tracking/yolov8_detection/runs_model_x/weights/best.pt'  # Ruta de mi modelo\n",
        "model = YOLO(model_path)"
      ],
      "metadata": {
        "id": "BKcLJH1eaghE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Detecci√≥n de gallinas en v√≠deo con nuestro modelo best.pt**"
      ],
      "metadata": {
        "id": "kPd6lmwuaCuj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results=model(\"/content/drive/MyDrive/Colab Notebooks/yolov8_tracking/Deep_SORT/deep_sort/videos/Vid_Corto2_50_Gallinas.mp4\",classes=0,save=True)"
      ],
      "metadata": {
        "id": "S0omqK17gLgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Tracking mediante BotSORT y Bytetrack**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "QoH38BMykQkX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir la fuente del video\n",
        "input_video = '/content/drive/MyDrive/Colab Notebooks/yolov8_tracking/Deep_SORT/deep_sort/videos/Vid_110_Gallinas.mp4'\n",
        "output_path_bytetrack = '/content/drive/MyDrive/Colab Notebooks/yolov8_tracking/Deep_SORT/deep_sort/videos/Result_Vid_50_Gallinas_ByteTrack.mp4'\n",
        "output_path_botsort = '/content/drive/MyDrive/Colab Notebooks/yolov8_tracking/Deep_SORT/deep_sort/videos/Result_Vid_110_BotSORT.mp4'\n",
        "trayectoria = '/content/drive/MyDrive/Colab Notebooks/yolov8_tracking/Deep_SORT/deep_sort/videos/Result_Vid_110T_BotSORT.mp4'"
      ],
      "metadata": {
        "id": "nBSeqh69rJo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Par√°metros para mejorar la detecci√≥n\n",
        "CONFIDENCE_THRESHOLD = 0.7  # Umbral de confianza para reducir falsos positivos\n",
        "MIN_TRACK_LENGTH = 5  # M√≠nima cantidad de posiciones para considerar un track v√°lido\n",
        "MIN_AREA = 500  # M√≠nimo tama√±o de un objeto detectado en p√≠xeles\n",
        "\n",
        "# Escala de conversi√≥n px ‚Üí cm (basado en el ancho de una gallina ‚âà 30 cm)\n",
        "ANCHO_GALLINA_CM = 30\n",
        "ANCHO_GALLINA_PX = 100  # Estima este valor de acuerdo a tus videos\n",
        "PX_TO_CM = ANCHO_GALLINA_CM / ANCHO_GALLINA_PX  # Conversi√≥n de p√≠xeles a cent√≠metros"
      ],
      "metadata": {
        "id": "VsEB-owXCSHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Variables para estad√≠sticas\n",
        "tracked_positions = {}\n",
        "frame_count = 0\n",
        "cantidad_vs_tiempo = []\n",
        "velocidad_vs_tiempo = []\n",
        "distancia_vs_tiempo = []"
      ],
      "metadata": {
        "id": "BnoVK1oJYEEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Funci√≥n encargada de dibujar los bounding box y realizar el seguimiento."
      ],
      "metadata": {
        "id": "6-wt0XlJ7PfH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_tracking(tracker_type, output_path, max_frames=10000):\n",
        "    global tracked_positions, frame_count, cantidad_vs_tiempo, velocidad_vs_tiempo, distancia_vs_tiempo\n",
        "\n",
        "    cantidad_vs_tiempo = []\n",
        "    results = model.track(source=input_video, persist=True, classes=0, tracker=tracker_type, conf=CONFIDENCE_THRESHOLD, stream=True)\n",
        "\n",
        "    cap = cv2.VideoCapture(input_video)\n",
        "    width = int(cap.get(3))\n",
        "    height = int(cap.get(4))\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "    sidebar_width = 200\n",
        "    new_width = width + sidebar_width\n",
        "\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (new_width, height))\n",
        "\n",
        "    frame_count = 0\n",
        "    tracked_positions = {}  # Almacenar todas las trayectorias detectadas\n",
        "\n",
        "    for result in results:\n",
        "        if result is None or frame_count >= max_frames or result.orig_img is None:\n",
        "            break\n",
        "\n",
        "        frame = result.orig_img.copy()\n",
        "        current_ids = set()\n",
        "\n",
        "        # --- TRACKING ---\n",
        "        if result.boxes is not None:\n",
        "            ids = result.boxes.id.int().cpu().tolist() if result.boxes.id is not None else []\n",
        "            boxes = result.boxes.xyxy.cpu().numpy()\n",
        "            confs = result.boxes.conf.cpu().numpy()\n",
        "\n",
        "            for i, box in enumerate(boxes):\n",
        "                x1, y1, x2, y2 = map(int, box)\n",
        "                track_id = ids[i] if i < len(ids) else -1\n",
        "                confidence = confs[i] if i < len(confs) else 0\n",
        "\n",
        "                if track_id != -1 and confidence > CONFIDENCE_THRESHOLD:\n",
        "                    center_x, center_y = (x1 + x2) // 2, (y1 + y2) // 2\n",
        "                    current_ids.add(track_id)\n",
        "\n",
        "                    # Guardar trayectoria\n",
        "                    if track_id not in tracked_positions:\n",
        "                        tracked_positions[track_id] = []\n",
        "                    tracked_positions[track_id].append((center_x, center_y))\n",
        "\n",
        "                    # Dibujar bounding box e ID en la imagen\n",
        "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "                    cv2.putText(frame, f'ID: {track_id}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "        # --- INTERFAZ VISUAL ---\n",
        "        sidebar = np.zeros((height, sidebar_width, 3), dtype=np.uint8)\n",
        "        cv2.putText(sidebar, f'Frame: {frame_count}', (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
        "        cv2.putText(sidebar, f'Gallinas: {len(current_ids)}', (20, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
        "\n",
        "        combined_frame = np.hstack((frame, sidebar))\n",
        "        out.write(combined_frame)\n",
        "\n",
        "        cantidad_vs_tiempo.append(len(current_ids))\n",
        "        frame_count += 1\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "\n",
        "    # üîπ Mostrar los IDs detectados al final del tracking\n",
        "    print(\"‚úÖ Tracking completado. Gallinas detectadas con los siguientes IDs:\")\n",
        "    print(list(tracked_positions.keys()))\n",
        "    print(\"üîπ Ingresa el ID de la gallina que quieres seguir en la funci√≥n draw_trajectory().\")"
      ],
      "metadata": {
        "id": "kCzuz01aWmjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Funci√≥n encargada de dibujar la trayectoria de la gallina preseleccionada."
      ],
      "metadata": {
        "id": "wS2qRzV57Z63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_trajectory(selected_chicken_id, input_video_path, output_video_path):\n",
        "    global distancia_vs_tiempo, velocidad_vs_tiempo\n",
        "\n",
        "    if selected_chicken_id not in tracked_positions:\n",
        "        print(f\"‚ùå No hay datos para la gallina con ID {selected_chicken_id}\")\n",
        "        return\n",
        "\n",
        "    cap = cv2.VideoCapture(input_video_path)\n",
        "    width = int(cap.get(3))\n",
        "    height = int(cap.get(4))\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
        "\n",
        "    posiciones = np.array(tracked_positions[selected_chicken_id])\n",
        "    if len(posiciones) < 2:\n",
        "        print(f\"‚ö†Ô∏è No hay suficientes datos para calcular distancia y velocidad de la gallina con ID {selected_chicken_id}\")\n",
        "        return\n",
        "\n",
        "    distancia_vs_tiempo = []\n",
        "    velocidad_vs_tiempo = []\n",
        "\n",
        "    # C√°lculo de distancia y velocidad\n",
        "    difs = np.diff(posiciones, axis=0)\n",
        "    distancia_px = np.linalg.norm(difs, axis=1).cumsum()\n",
        "    distancia_cm = distancia_px * PX_TO_CM\n",
        "    velocidad_cm_s = np.gradient(distancia_cm) * fps  # Aproximaci√≥n de velocidad\n",
        "\n",
        "    # Posici√≥n fija en la esquina superior izquierda (4 cm hacia abajo)\n",
        "    text_x = 20  # Separado del borde izquierdo\n",
        "    text_y = int(4 / PX_TO_CM) + 20  # Convertir 4 cm a p√≠xeles y ajustar\n",
        "\n",
        "    frame_count = 0\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret or frame_count >= len(posiciones):\n",
        "            break\n",
        "\n",
        "        # Dibujar trayectoria acumulada hasta el frame actual\n",
        "        for j in range(1, frame_count + 1):\n",
        "            if j < len(posiciones):\n",
        "                cv2.line(frame, tuple(posiciones[j - 1]), tuple(posiciones[j]), (255, 0, 0), 4)\n",
        "\n",
        "        # üìå Agregar distancia y velocidad en la esquina superior izquierda\n",
        "        if frame_count < len(distancia_cm):\n",
        "            cv2.putText(frame, f'Dist: {distancia_cm[frame_count]:.2f} cm', (1100, text_y + 118),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
        "            cv2.putText(frame, f'Vel: {velocidad_cm_s[frame_count]:.2f} cm/s', (1100, text_y + 170),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
        "\n",
        "            distancia_vs_tiempo.append(distancia_cm[frame_count])\n",
        "            velocidad_vs_tiempo.append(velocidad_cm_s[frame_count])\n",
        "\n",
        "        out.write(frame)\n",
        "        frame_count += 1\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    print(\"‚úÖ Video con trayectoria, distancia y velocidad generado correctamente.\")"
      ],
      "metadata": {
        "id": "j1IiHr6AWsdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Funci√≥n encargada de realizar los gr√°ficos de Cantidad, Distancia y Velocidad vs Tiempo (Frames)"
      ],
      "metadata": {
        "id": "Oq_U1LKO7oAM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_metrics():\n",
        "    global cantidad_vs_tiempo, distancia_vs_tiempo, velocidad_vs_tiempo\n",
        "\n",
        "    tiempo_frames_cantidad = np.arange(len(cantidad_vs_tiempo))\n",
        "    tiempo_frames_tracking = np.arange(len(distancia_vs_tiempo))\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # üîπ Cantidad de gallinas vs tiempo\n",
        "    plt.subplot(3, 1, 1)\n",
        "    plt.plot(tiempo_frames_cantidad, cantidad_vs_tiempo, label='Cantidad de gallinas', color='b')\n",
        "    plt.xlabel('Tiempo (frames)')\n",
        "    plt.ylabel('Cantidad')\n",
        "    plt.legend()\n",
        "\n",
        "    # üîπ Velocidad vs tiempo\n",
        "    plt.subplot(3, 1, 2)\n",
        "    plt.plot(tiempo_frames_tracking, velocidad_vs_tiempo, label='Velocidad (cm/s)', color='r')\n",
        "    plt.xlabel('Tiempo (frames)')\n",
        "    plt.ylabel('Velocidad (cm/s)')\n",
        "    plt.legend()\n",
        "\n",
        "    # üîπ Distancia vs tiempo\n",
        "    plt.subplot(3, 1, 3)\n",
        "    plt.plot(tiempo_frames_tracking, distancia_vs_tiempo, label='Distancia recorrida (cm)', color='g')\n",
        "    plt.xlabel('Tiempo (frames)')\n",
        "    plt.ylabel('Distancia (cm)')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "2aTRNaXsYBTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Ejecuta el tracking mediante ByteTrack"
      ],
      "metadata": {
        "id": "AlAhZk_C70-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "process_tracking('bytetrack.yaml', output_path_bytetrack)"
      ],
      "metadata": {
        "id": "YEnDe4sz_ryv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Ejecuta el tracking mediante BotSORT"
      ],
      "metadata": {
        "id": "24Jjk0h879m_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "process_tracking('botsort.yaml', output_path_botsort)"
      ],
      "metadata": {
        "id": "6FBLidOW_wOI",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Se escoge la gallina a la cual se le medir√° y dibujar√° la trayectoria."
      ],
      "metadata": {
        "id": "yYCVu0S68A6w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "draw_trajectory(306, output_path_botsort, trayectoria)"
      ],
      "metadata": {
        "id": "fZn3eB3TYLJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Grafica los resultados obtenidos"
      ],
      "metadata": {
        "id": "_mslgpz98Ij5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Graficar m√©tricas\n",
        "plot_metrics()"
      ],
      "metadata": {
        "id": "vhaqubkiYSL-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}