{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KK7F9ZxiAsL"
      },
      "source": [
        "##**Modelo de Detección**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Librerías"
      ],
      "metadata": {
        "id": "jdzBvkup3sCh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "IA51hFbzjwcl"
      },
      "outputs": [],
      "source": [
        "# Instalar ultralytics para YOLO\n",
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "DCzPsGBYn6Di"
      },
      "outputs": [],
      "source": [
        "# Importar librerías\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "from google.colab import drive\n",
        "import os\n",
        "import time\n",
        "import cv2\n",
        "import numpy as np\n",
        "import yaml\n",
        "import colorsys\n",
        "import torch.backends.cudnn as cudnn\n",
        "from PIL import Image\n",
        "from collections import defaultdict\n",
        "import albumentations as A\n",
        "import random\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Acceso a Gooogle Drive"
      ],
      "metadata": {
        "id": "RzMqVFLR4JaY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0SSUXTVsHxe"
      },
      "outputs": [],
      "source": [
        "# Montar Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Seleccionamos el modelo YOLO."
      ],
      "metadata": {
        "id": "U-rHIm6R4UFZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "F0e4CQG6oer-"
      },
      "outputs": [],
      "source": [
        "# Configurar los parámetros del modelo YOLOV11X\n",
        "model = YOLO('yolo11x.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Aumento de las imágenes para el entrenamiento"
      ],
      "metadata": {
        "id": "-bFNpNNBheQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rutas de carpetas en Google Drive\n",
        "train_folder = \"/content/drive/MyDrive/Colab Notebooks/yolov8_tracking/yolov8_detection/hen_detection_dataset/train/images\"\n",
        "label_folder = \"/content/drive/MyDrive/Colab Notebooks/yolov8_tracking/yolov8_detection/hen_detection_dataset/train/labels\"\n",
        "os.makedirs(train_folder, exist_ok=True)\n",
        "os.makedirs(label_folder, exist_ok=True)\n",
        "\n",
        "# Obtener lista de imágenes en train\n",
        "image_files = [f for f in os.listdir(train_folder) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
        "random.shuffle(image_files)  # Mezclar imágenes para selección aleatoria"
      ],
      "metadata": {
        "id": "OKghAfvthh0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Número total de imágenes en train\n",
        "total_images = len(image_files)\n",
        "images_per_augmentation = round(total_images / 4)  # Distribuir imágenes equitativamente entre 4 técnicas\n",
        "\n",
        "# Dividir imágenes en grupos dinámicos según la cantidad en train\n",
        "noise_images = image_files[:images_per_augmentation]\n",
        "gray_images = image_files[images_per_augmentation:images_per_augmentation*2]\n",
        "brightness_images = image_files[images_per_augmentation*2:images_per_augmentation*3]\n",
        "saturation_images = image_files[images_per_augmentation*3:]"
      ],
      "metadata": {
        "id": "kM_sNyNLhlyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir transformaciones\n",
        "transforms = {\n",
        "    \"noise\": A.GaussNoise(var_limit=(10.0, 50.0), p=1.0),\n",
        "    \"gray\": A.ToGray(p=1.0),\n",
        "    \"brightness\": A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=1.0),\n",
        "    \"saturation\": A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=30, val_shift_limit=20, p=1.0)\n",
        "}"
      ],
      "metadata": {
        "id": "tE83yVi0ht1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicar transformaciones y guardar imágenes con etiquetas\n",
        "def apply_augmentation(image_list, transform, prefix):\n",
        "    for img_file in image_list:\n",
        "        img_path = os.path.join(train_folder, img_file)\n",
        "        label_path = os.path.join(label_folder, os.path.splitext(img_file)[0] + \".txt\")\n",
        "\n",
        "        image = cv2.imread(img_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        augmented = transform(image=image)['image']\n",
        "        output_img_path = os.path.join(train_folder, f\"{prefix}_{img_file}\")\n",
        "        Image.fromarray(augmented).save(output_img_path)\n",
        "\n",
        "        # Copiar etiqueta si existe\n",
        "        if os.path.exists(label_path):\n",
        "            output_label_path = os.path.join(label_folder, f\"{prefix}_{img_file.replace('.jpg', '.txt').replace('.png', '.txt').replace('.jpeg', '.txt')}\")\n",
        "            shutil.copy(label_path, output_label_path)\n",
        "\n",
        "apply_augmentation(noise_images, transforms[\"noise\"], \"noise\")\n",
        "apply_augmentation(gray_images, transforms[\"gray\"], \"gray\")\n",
        "apply_augmentation(brightness_images, transforms[\"brightness\"], \"brightness\")\n",
        "apply_augmentation(saturation_images, transforms[\"saturation\"], \"saturation\")\n",
        "\n",
        "print(f\"Aumento de imágenes completado. Total de imágenes generadas: {len(os.listdir(train_folder)) - total_images}\")"
      ],
      "metadata": {
        "id": "EuE4JOfch_p5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Entrenamiento del modelo de detección"
      ],
      "metadata": {
        "id": "vbblrxDmiE-C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMLU2mqBos69"
      },
      "outputs": [],
      "source": [
        "model.train(\n",
        "    data='/content/drive/MyDrive/Colab Notebooks/yolov8_tracking/yolov8_detection/data.yaml',   # Archivo de configuración de los datos\n",
        "    epochs=100,                             # Número de épocas de entrenamiento\n",
        "    batch=32,                               # Tamaño del batch (ajusta si ves que consume demasiada RAM)\n",
        "    imgsz=640,                             # Tamaño de la imagen (640x640 en este caso)\n",
        "    cache=True                             # Cachear las imágenes para reducir la carga de lectura\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6vwgVkuc1zl"
      },
      "source": [
        "###Realizamos las predicciones a partir del modelo 'best.pt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "gfjlMPY2aChV"
      },
      "outputs": [],
      "source": [
        "# Cargar el modelo entrenado (después del entrenamiento)\n",
        "model = YOLO('/content/drive/MyDrive/Colab Notebooks/yolov8_tracking/yolov8_detection/runs_model_x/weights/best.pt')\n",
        "\n",
        "# Directorio de las imágenes de prueba\n",
        "test_images_path = '/content/drive/MyDrive/Colab Notebooks/yolov8_tracking/yolov8_detection/test/images'\n",
        "\n",
        "# Realizar predicciones en las imágenes de prueba\n",
        "results = model.predict(\n",
        "    source=test_images_path,       # Ruta a la carpeta de imágenes de prueba\n",
        "    conf=0.5,                      # Umbral de confianza para detecciones\n",
        "    save=True,                     # Guardar las imágenes con los resultados\n",
        "    save_txt=True,                 # Guardar las etiquetas predichas en formato .txt\n",
        "    project='/content/drive/MyDrive/Colab Notebooks/yolov8_tracking/yolov8_detection/test',  # Carpeta donde se guardarán los resultados\n",
        "    name='predictions'             # Subcarpeta donde se almacenarán los resultados\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xz_gPDW7dBjb"
      },
      "source": [
        "###Realizamos el conteo de las gallinas en cada imagen que predijo el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "iHd-gRpEca18"
      },
      "outputs": [],
      "source": [
        "# Contar gallinas por imagen\n",
        "image_hen_counts = {}\n",
        "for result in results:\n",
        "    image_name = result.path.split(\"/\")[-1]  # Obtener el nombre de la imagen\n",
        "    detections = result.boxes  # Obtener las detecciones\n",
        "    count = len(detections)  # Contar las detecciones en esta imagen\n",
        "    image_hen_counts[image_name] = count  # Guardar el conteo\n",
        "\n",
        "# Mostrar resultados\n",
        "for image, count in image_hen_counts.items():\n",
        "    print(f\"{image}: {count} gallinas detectadas\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Ruta de nuestro Modelo de detección"
      ],
      "metadata": {
        "id": "rZWudXsiahh8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurar el modelo YOLOv11 con tu modelo entrenado\n",
        "model_path = '/content/drive/MyDrive/Colab Notebooks/yolov8_tracking/yolov8_detection/runs_model_x/weights/best.pt'  # Ruta de mi modelo\n",
        "model = YOLO(model_path)"
      ],
      "metadata": {
        "id": "BKcLJH1eaghE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Detección de gallinas en vídeo con nuestro modelo best.pt**"
      ],
      "metadata": {
        "id": "kPd6lmwuaCuj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results=model(\"/content/drive/MyDrive/Colab Notebooks/yolov8_tracking/Deep_SORT/deep_sort/videos/Vid_Corto2_50_Gallinas.mp4\",classes=0,save=True)"
      ],
      "metadata": {
        "id": "S0omqK17gLgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Tracking mediante BotSORT y Bytetrack**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "QoH38BMykQkX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir la fuente del video\n",
        "input_video = '/content/drive/MyDrive/Colab Notebooks/yolov8_tracking/Deep_SORT/deep_sort/videos/Vid_110_Gallinas.mp4'\n",
        "output_path_bytetrack = '/content/drive/MyDrive/Colab Notebooks/yolov8_tracking/Deep_SORT/deep_sort/videos/Result_Vid_50_Gallinas_ByteTrack.mp4'\n",
        "output_path_botsort = '/content/drive/MyDrive/Colab Notebooks/yolov8_tracking/Deep_SORT/deep_sort/videos/Result_Vid_110_BotSORT.mp4'\n",
        "trayectoria = '/content/drive/MyDrive/Colab Notebooks/yolov8_tracking/Deep_SORT/deep_sort/videos/Result_Vid_110T_BotSORT.mp4'"
      ],
      "metadata": {
        "id": "nBSeqh69rJo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parámetros para mejorar la detección\n",
        "CONFIDENCE_THRESHOLD = 0.7  # Umbral de confianza para reducir falsos positivos\n",
        "MIN_TRACK_LENGTH = 5  # Mínima cantidad de posiciones para considerar un track válido\n",
        "MIN_AREA = 500  # Mínimo tamaño de un objeto detectado en píxeles\n",
        "\n",
        "# Escala de conversión px → cm (basado en el ancho de una gallina ≈ 30 cm)\n",
        "ANCHO_GALLINA_CM = 30\n",
        "ANCHO_GALLINA_PX = 100  # Estima este valor de acuerdo a tus videos\n",
        "PX_TO_CM = ANCHO_GALLINA_CM / ANCHO_GALLINA_PX  # Conversión de píxeles a centímetros"
      ],
      "metadata": {
        "id": "VsEB-owXCSHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Variables para estadísticas\n",
        "tracked_positions = {}\n",
        "frame_count = 0\n",
        "cantidad_vs_tiempo = []\n",
        "velocidad_vs_tiempo = []\n",
        "distancia_vs_tiempo = []"
      ],
      "metadata": {
        "id": "BnoVK1oJYEEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Función encargada de dibujar los bounding box y realizar el seguimiento."
      ],
      "metadata": {
        "id": "6-wt0XlJ7PfH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_tracking(tracker_type, output_path, max_frames=10000):\n",
        "    global tracked_positions, frame_count, cantidad_vs_tiempo, velocidad_vs_tiempo, distancia_vs_tiempo\n",
        "\n",
        "    cantidad_vs_tiempo = []\n",
        "    results = model.track(source=input_video, persist=True, classes=0, tracker=tracker_type, conf=CONFIDENCE_THRESHOLD, stream=True)\n",
        "\n",
        "    cap = cv2.VideoCapture(input_video)\n",
        "    width = int(cap.get(3))\n",
        "    height = int(cap.get(4))\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "    sidebar_width = 200\n",
        "    new_width = width + sidebar_width\n",
        "\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (new_width, height))\n",
        "\n",
        "    frame_count = 0\n",
        "    tracked_positions = {}  # Almacenar todas las trayectorias detectadas\n",
        "\n",
        "    for result in results:\n",
        "        if result is None or frame_count >= max_frames or result.orig_img is None:\n",
        "            break\n",
        "\n",
        "        frame = result.orig_img.copy()\n",
        "        current_ids = set()\n",
        "\n",
        "        # --- TRACKING ---\n",
        "        if result.boxes is not None:\n",
        "            ids = result.boxes.id.int().cpu().tolist() if result.boxes.id is not None else []\n",
        "            boxes = result.boxes.xyxy.cpu().numpy()\n",
        "            confs = result.boxes.conf.cpu().numpy()\n",
        "\n",
        "            for i, box in enumerate(boxes):\n",
        "                x1, y1, x2, y2 = map(int, box)\n",
        "                track_id = ids[i] if i < len(ids) else -1\n",
        "                confidence = confs[i] if i < len(confs) else 0\n",
        "\n",
        "                if track_id != -1 and confidence > CONFIDENCE_THRESHOLD:\n",
        "                    center_x, center_y = (x1 + x2) // 2, (y1 + y2) // 2\n",
        "                    current_ids.add(track_id)\n",
        "\n",
        "                    # Guardar trayectoria\n",
        "                    if track_id not in tracked_positions:\n",
        "                        tracked_positions[track_id] = []\n",
        "                    tracked_positions[track_id].append((center_x, center_y))\n",
        "\n",
        "                    # Dibujar bounding box e ID en la imagen\n",
        "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "                    cv2.putText(frame, f'ID: {track_id}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "        # --- INTERFAZ VISUAL ---\n",
        "        sidebar = np.zeros((height, sidebar_width, 3), dtype=np.uint8)\n",
        "        cv2.putText(sidebar, f'Frame: {frame_count}', (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
        "        cv2.putText(sidebar, f'Gallinas: {len(current_ids)}', (20, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
        "\n",
        "        combined_frame = np.hstack((frame, sidebar))\n",
        "        out.write(combined_frame)\n",
        "\n",
        "        cantidad_vs_tiempo.append(len(current_ids))\n",
        "        frame_count += 1\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "\n",
        "    # 🔹 Mostrar los IDs detectados al final del tracking\n",
        "    print(\"✅ Tracking completado. Gallinas detectadas con los siguientes IDs:\")\n",
        "    print(list(tracked_positions.keys()))\n",
        "    print(\"🔹 Ingresa el ID de la gallina que quieres seguir en la función draw_trajectory().\")"
      ],
      "metadata": {
        "id": "kCzuz01aWmjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Función encargada de dibujar la trayectoria de la gallina preseleccionada."
      ],
      "metadata": {
        "id": "wS2qRzV57Z63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_trajectory(selected_chicken_id, input_video_path, output_video_path):\n",
        "    global distancia_vs_tiempo, velocidad_vs_tiempo\n",
        "\n",
        "    if selected_chicken_id not in tracked_positions:\n",
        "        print(f\"❌ No hay datos para la gallina con ID {selected_chicken_id}\")\n",
        "        return\n",
        "\n",
        "    cap = cv2.VideoCapture(input_video_path)\n",
        "    width = int(cap.get(3))\n",
        "    height = int(cap.get(4))\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
        "\n",
        "    posiciones = np.array(tracked_positions[selected_chicken_id])\n",
        "    if len(posiciones) < 2:\n",
        "        print(f\"⚠️ No hay suficientes datos para calcular distancia y velocidad de la gallina con ID {selected_chicken_id}\")\n",
        "        return\n",
        "\n",
        "    distancia_vs_tiempo = []\n",
        "    velocidad_vs_tiempo = []\n",
        "\n",
        "    # Cálculo de distancia y velocidad\n",
        "    difs = np.diff(posiciones, axis=0)\n",
        "    distancia_px = np.linalg.norm(difs, axis=1).cumsum()\n",
        "    distancia_cm = distancia_px * PX_TO_CM\n",
        "    velocidad_cm_s = np.gradient(distancia_cm) * fps  # Aproximación de velocidad\n",
        "\n",
        "    # Posición fija en la esquina superior izquierda (4 cm hacia abajo)\n",
        "    text_x = 20  # Separado del borde izquierdo\n",
        "    text_y = int(4 / PX_TO_CM) + 20  # Convertir 4 cm a píxeles y ajustar\n",
        "\n",
        "    frame_count = 0\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret or frame_count >= len(posiciones):\n",
        "            break\n",
        "\n",
        "        # Dibujar trayectoria acumulada hasta el frame actual\n",
        "        for j in range(1, frame_count + 1):\n",
        "            if j < len(posiciones):\n",
        "                cv2.line(frame, tuple(posiciones[j - 1]), tuple(posiciones[j]), (255, 0, 0), 4)\n",
        "\n",
        "        # 📌 Agregar distancia y velocidad en la esquina superior izquierda\n",
        "        if frame_count < len(distancia_cm):\n",
        "            cv2.putText(frame, f'Dist: {distancia_cm[frame_count]:.2f} cm', (1100, text_y + 118),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
        "            cv2.putText(frame, f'Vel: {velocidad_cm_s[frame_count]:.2f} cm/s', (1100, text_y + 170),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
        "\n",
        "            distancia_vs_tiempo.append(distancia_cm[frame_count])\n",
        "            velocidad_vs_tiempo.append(velocidad_cm_s[frame_count])\n",
        "\n",
        "        out.write(frame)\n",
        "        frame_count += 1\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    print(\"✅ Video con trayectoria, distancia y velocidad generado correctamente.\")"
      ],
      "metadata": {
        "id": "j1IiHr6AWsdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Función encargada de realizar los gráficos de Cantidad, Distancia y Velocidad vs Tiempo (Frames)"
      ],
      "metadata": {
        "id": "Oq_U1LKO7oAM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_metrics():\n",
        "    global cantidad_vs_tiempo, distancia_vs_tiempo, velocidad_vs_tiempo\n",
        "\n",
        "    tiempo_frames_cantidad = np.arange(len(cantidad_vs_tiempo))\n",
        "    tiempo_frames_tracking = np.arange(len(distancia_vs_tiempo))\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # 🔹 Cantidad de gallinas vs tiempo\n",
        "    plt.subplot(3, 1, 1)\n",
        "    plt.plot(tiempo_frames_cantidad, cantidad_vs_tiempo, label='Cantidad de gallinas', color='b')\n",
        "    plt.xlabel('Tiempo (frames)')\n",
        "    plt.ylabel('Cantidad')\n",
        "    plt.legend()\n",
        "\n",
        "    # 🔹 Velocidad vs tiempo\n",
        "    plt.subplot(3, 1, 2)\n",
        "    plt.plot(tiempo_frames_tracking, velocidad_vs_tiempo, label='Velocidad (cm/s)', color='r')\n",
        "    plt.xlabel('Tiempo (frames)')\n",
        "    plt.ylabel('Velocidad (cm/s)')\n",
        "    plt.legend()\n",
        "\n",
        "    # 🔹 Distancia vs tiempo\n",
        "    plt.subplot(3, 1, 3)\n",
        "    plt.plot(tiempo_frames_tracking, distancia_vs_tiempo, label='Distancia recorrida (cm)', color='g')\n",
        "    plt.xlabel('Tiempo (frames)')\n",
        "    plt.ylabel('Distancia (cm)')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "2aTRNaXsYBTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Ejecuta el tracking mediante ByteTrack"
      ],
      "metadata": {
        "id": "AlAhZk_C70-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "process_tracking('bytetrack.yaml', output_path_bytetrack)"
      ],
      "metadata": {
        "id": "YEnDe4sz_ryv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Ejecuta el tracking mediante BotSORT"
      ],
      "metadata": {
        "id": "24Jjk0h879m_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "process_tracking('botsort.yaml', output_path_botsort)"
      ],
      "metadata": {
        "id": "6FBLidOW_wOI",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Se escoge la gallina a la cual se le medirá y dibujará la trayectoria."
      ],
      "metadata": {
        "id": "yYCVu0S68A6w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "draw_trajectory(306, output_path_botsort, trayectoria)"
      ],
      "metadata": {
        "id": "fZn3eB3TYLJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Grafica los resultados obtenidos"
      ],
      "metadata": {
        "id": "_mslgpz98Ij5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Graficar métricas\n",
        "plot_metrics()"
      ],
      "metadata": {
        "id": "vhaqubkiYSL-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}